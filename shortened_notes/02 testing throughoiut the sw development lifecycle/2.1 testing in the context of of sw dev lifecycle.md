# 2.1 Testing in the Context of a Software Development Lifecycle

**SDLC model** def.:
* **an abstract, high-level representation of the software development process**
* defines **how different development phases & types of activities** performed within this process **relate to each other**
  + logically,
  + chronologically
* examples:
  + **sequential development models**
    - *waterfall model*, *V-model*
  + **iterative development models**
    - *spiral model*, *prototyping*
  + **incremental development models**
    - *Unified Process*

**more detailed software development methods & Agile practices**:
* (**some activities** within software development processes can also be described by these)
* *acceptance test-driven development* (ATDD)
* *behavior-driven development* (BDD)
* domain-driven design (DDD)
* *extreme programming* (XP)
* feature-driven development (FDD)
* Kanban
* Lean IT
* Scrum
* *test-driven development* (TDD)

## 2.1.1 Impact of the SDLC on Testing

**testing must be adapted to the SDLC** – **the choice of the SDLC impacts on the:**
* scope & timing of test activities (e.g., *test levels* and *test types*)
* level of detail of test documentation
* choice of *test techniques* & *test approach*
* extent of *test automation*
* role & responsibilities of a tester

**in sequential development models**
* in the initial phases testers typically participate in
  + requirement *reviews*,
  + *test analysis*,
  + *test design*
* the executable code is usually created in the later phases,
  + so typically *dynamic testing* cannot be performed early in the SDLC

**in some iterative & incremental development models**
* it is assumed that each iteration delivers a working prototype or product increment
* this implies that in each iteration both *static* & *dynamic testing* may be performed at all *test levels*
* frequent delivery of increments requires fast feedback & extensive *regression testing*

**Agile software development**
* assumes that change may occur throughout the project
* so lightweight work product documentation & extensive *test automation* are favored
  + to make *regression testing* easier
* also, most of the manual testing is done using *experience-based test techniques*
  + that do not require extensive prior *test analysis* & *test design*

## 2.1.2 SDLC and Good Testing Practices

**good testing practices, independent of the chosen SDLC model**, include:
* **for every software development activity** –> a **corresponding test activity**,
  + so that all dev activities are subject to *quality control*
* **different *test levels*** have **specific & different *test objectives***,
  + allows for testing to be appropriately comprehensive while avoiding redundancy
* ***test analysis* & *test design*** for a given *test level* **begins during the corresponding dev phase** of the SDLC,
  + so that testing can adhere to the principle of early testing
* **testers are involved in reviewing work products as soon as drafts of** this documentation are available,
  + so that this earlier testing & *defect* detection can support the *shift-left strategy*

## 2.1.3 Testing as a Driver for Software Development

**TDD**, **ATDD** & **BDD** are similar development approaches: **tests are a means of directing development**
* each **implements the principle of early testing** & follows a *shift-left* approach
  + since tests are defined before the code is written
* they **support an iterative development model**

**Test-Driven Development (TDD):**
* **directs the coding through *test cases*** (instead of extensive software design)
* tests are written **first**,
  + **then** the code is written to satisfy the tests,
  + **then** the tests & code are refactored

**Acceptance Test-Driven Development (ATDD)**:
* **derives tests from acceptance criteria** as part of the system design process
* **tests are written before the part of the application** is developed to satisfy the tests

**Behavior-Driven Development (BDD):**
* expresses the **desired behavior of an application with *test cases* written in simple natural language**,
  + which is easy to understand by stakeholders
  + usually using the **Given/When/Then format**
* ***test cases*** are then **automatically [?] translated into executable tests**

for all the above approaches, **tests may persist as automated tests** to ensure code quality in future
* adaptions
* refactoring

## 2.1.4 DevOps and Testing

**DevOps** def.:
* is an **organizational approach** aiming **to create synergy**
  + by getting **development** (including testing) & **operations** to work together
    - to achieve a set of common goals
* **requires a cultural shift** within an organization
  + to bridge the gaps between dev (incl. testing) & operations
  + while treating their functions with equal value
* it **promotes**:
  + team autonomy,
  + fast feedback,
  + integrated toolchains & technical practices like
    - continuous integration (CI)
    - continuous delivery (CD)
* this **enables** the teams to **build, test & release high-quality code** faster
  + through a **DevOps delivery pipeline**

**benefits of DevOps, from the testing perspective**, include:
* **fast feedback on** the code quality & whether changes adversely affect existing code
* **CI promotes a *shift-left approach* in testing**
  + encouraging devs to submit high quality code accompanied by *component tests* & *static analysis*
* **promotes automated processes like CI/CD** that facilitate establishing stable test environments
* **increases the view on non-functional quality** characteristics
  + eg. performance & reliability
* ***automation*** through a delivery pipeline **reduces the need for repetitive manual testing**
* the ***risk* in *regression* is minimized due to** the scale & range of automated *regression tests*
* **DevOps is not without its *risks* & challenges**, eg.:
  + the **DevOps delivery pipeline** must be **defined & established**
  + **CI / CD tools** must be **introduced & maintained**
  + ***test automation* requires additional resources** & may be difficult to establish & maintain

although DevOps comes with a high level of automated testing,
* **manual testing** – esp. from the user's perspective – **will still be needed**

## 2.1.5 Shift-Left Approach

the **principle of early testing** is sometimes referred to as ***shift-left***
* an approach where testing is performed earlier in the SDLC
* it suggests that testing should be done earlier
  + eg. not waiting for code to be implemented or for components to be integrated
* **but it does not mean** that testing later in the SDLC should be neglected

there are some **good practices to achieve a “shift-left” in testing**, eg.:
* **reviewing the specification from the perspective of testing**
  + these *review* activities on specs often find potential *defects*,
  + such as ambiguities, incompleteness, and inconsistencies
* **writing *test cases* before the code** is written & **have the code run in a test harness** during code implementation
* **using CI & even better CD**
  + as it comes with fast feedback & automated component tests to accompany source code when it is submitted to the code repository
* completing ***static analysis* of source code prior to *dynamic testing***, or as part of an automated process
* performing ***non-functional testing* starting at the component *test level***, where possible
  + this is a form of *shift-left* as these *non-functional test* types tend to be performed later in the SDLC
    - when a complete system & a representative test environment are available

a shift-left approach might result in **extra training, effort and/or costs earlier** in the process
* but is expected to save efforts and/or costs later in the process

for the *shift-left* approach it is important that **stakeholders are convinced & bought into** this concept

## 2.1.6 Retrospectives & Process Improvement

**retrospectives** def.:
* aka post-project meetings / project retrospectives
* often held at the end of a project or an iteration, at a release milestone, or can be held when needed
* timing & organization depend on the particular SDLC model being followed
* **participants**
  + not only testers, but also eg. developers, architects, product owner, business analysts
* **they discuss**:
  + What was successful & should be retained?
  + What was not successful & could be improved?
  + How to incorporate the improvements & retain the successes in the future?
* ***results* should be recorded** & are normally **part of the *test completion* report**
* retrospectives are **critical for** the successful implementation of **continuous improvement**
  + it is important that any recommended improvements are followed up

**typical benefits for testing** include:
* **increased test effectiveness / efficiency**
  + eg. by implementing suggestions for process improvement
* **increased quality of testware**
  + eg. by jointly reviewing the test processes
* **team bonding & learning**
  + eg. as a result of the opportunity to raise issues & propose improvement points
* **improved quality of the *test basis***
  + eg. as deficiencies in the extent & quality of the requirements could be addressed & solved
* **better cooperation between development & testing**
  + eg. as collaboration is reviewed & optimized regularly

